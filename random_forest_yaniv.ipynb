{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORe33FoDxz3YFjz7vkFqU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaniv496/Data-Science-Projects/blob/main/random_forest_yaniv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcG4u_0WKPpz"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def plot_plt():\n",
        "    train = pd.read_csv('train.csv')\n",
        "\n",
        "    # Select the relevant features\n",
        "    features = ['SalePrice', 'ModelID']\n",
        "    X = train[features]\n",
        "\n",
        "    # Scatter plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X['SalePrice'], X['MachineHoursCurrentMeter'], alpha=0.5)\n",
        "    plt.title('Scatter Plot of Feature1 vs Feature2')\n",
        "    plt.xlabel('Feature1')\n",
        "    plt.ylabel('Feature2')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def pair_plot():\n",
        "    features = ['ModelID', 'machine_age']\n",
        "    #sns.pairplot(train[features + ['SalePrice']])\n",
        "    plt.show()\n",
        "\n",
        "def RMSE(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "\n",
        "def base_model():\n",
        "    #read train data:\n",
        "    train = pd.read_csv('train.csv')\n",
        "    # calculate perdicition\n",
        "    baseline_prediction = train['SalePrice'].mean()\n",
        "\n",
        "    # Create a submission file\n",
        "\n",
        "    # read the the new data\n",
        "    valid = pd.read_csv('valid.csv')\n",
        "\n",
        "    # create new file with new data - id and the prediction value and save data to file\n",
        "    submission = pd.DataFrame({'SalesID': valid['SalesID'], 'SalePrice': baseline_prediction})\n",
        "\n",
        "    submission.to_csv('baseline_submission.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def RandomForest():\n",
        "\n",
        "    def download_from_gdrive(url, filename):\n",
        "        # Extract the file ID from the URL\n",
        "        file_id = url.split('/')[-2]\n",
        "        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "        # Download the file\n",
        "        if Path(filename).exists():\n",
        "            print(f\"File '{filename}' already exists. Skipping download.\")\n",
        "        else:\n",
        "            gdown.download(download_url, filename, quiet=False)\n",
        "            print(f\"File downloaded as: {filename}\")\n",
        "\n",
        "    train = 'https://drive.google.com/file/d/1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5/view?usp=drive_link'\n",
        "    valid = 'https://drive.google.com/file/d/1j7x8xhMimKbvW62D-XeDfuRyj9ia636q/view?usp=drive_link'\n",
        "    download_from_gdrive(train, 'train.csv')\n",
        "    download_from_gdrive(valid, 'valid.csv')\n",
        "\n",
        "\n",
        "    train = pd.read_csv('train.csv')\n",
        "    valid = pd.read_csv('valid.csv')\n",
        "    #train.head() # inspect the first row of data\n",
        "    train['saleyeardate'] = None\n",
        "    valid['saleyeardate'] = None\n",
        "    # #add train age features\n",
        "    #\n",
        "    train['saleyeardate'] = pd.to_datetime(train['saledate']).dt.year\n",
        "    valid['saleyeardate'] = pd.to_datetime(valid['saledate']).dt.year\n",
        "\n",
        "#--------------- background calc\n",
        "    # calculate mean without year - > 1000 on  YearMade feature\n",
        "    # Filter out the specific value\n",
        "    #filtered_data = train[train['YearMade'] != 1000]\n",
        "\n",
        "    # Calculate the mean of the filtered feature\n",
        "    #mean_value = filtered_data['YearMade'].mean()\n",
        "    # the result of mean is 1994 in train\n",
        "    #--------------\n",
        "   #filtered_data = valid[valid['YearMade'] != 1000]\n",
        "    #mean_value = filtered_data['YearMade'].mean()\n",
        "    # the result of mean is 1999 in valid\n",
        "\n",
        "\n",
        "    # update the mean 1994 (train) 1999 (valid) while the value is 1000 in YearMade\n",
        "    # train.loc[train['YearMade'] == 1000, 'YearMade'] = 1994\n",
        "    valid.loc[valid['YearMade'] == 1000, 'YearMade'] = 1999\n",
        "\n",
        "\n",
        "\n",
        "    # Drop the rows\n",
        "    train_c1 = train.drop(index=train[train['YearMade'] == 1000].index)\n",
        "    #valid_c1 = valid.drop(index=valid[valid['YearMade'] == 1000].index)\n",
        "\n",
        "    valid_c1 = valid\n",
        "    train_c1['machine_age'] = train_c1['saleyeardate'] - train_c1['YearMade']\n",
        "    valid_c1['machine_age'] = valid_c1['saleyeardate'] - valid_c1['YearMade']\n",
        "\n",
        "    train_c1 = train_c1.drop(index=train_c1[train_c1['machine_age'] < 0].index)\n",
        "    #valid_c1 = valid_c1.drop(index=valid_c1[valid_c1['machine_age'] < 0].index)\n",
        "\n",
        "\n",
        "\n",
        "    # clean train data\n",
        "    train_c1 = train_c1.select_dtypes('number')# drop all categorical variables\n",
        "    train_c1 = train_c1[train_c1['machine_age'] < 60]\n",
        "\n",
        "    train_c1 = train_c1.dropna()  # drop all rows with missing values\n",
        "    train_c1 = train_c1.set_index('SalesID')\n",
        "\n",
        "\n",
        "    # Split the data\n",
        "    X = train_c1.drop(columns=['SalePrice'])\n",
        "    y = train_c1['SalePrice']\n",
        "    #test_size - > % from tha data for testing and the other for training\n",
        "\n",
        "    # plots\n",
        "    # features_list = ['ModelID', 'machine_age']\n",
        "    # sns.pairplot(train_c1[features_list + ['SalePrice']])\n",
        "    # plt.show()\n",
        "\n",
        "    # random_state - An integer value ensures that the  results are reproducible\n",
        "    test_size = 0.1 # ( 25% - testing , 75% - training)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model = RandomForestRegressor(random_state=42,n_estimators=300, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    #print(pd.Series(model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False))\n",
        "\n",
        "\n",
        "    # Validate the model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'Train RMSE: {RMSE(y_train, y_train_pred)}')\n",
        "    print(f'Test RMSE: {RMSE(y_test, y_test_pred)}')\n",
        "\n",
        "    # Clean and prepare validation data\n",
        "\n",
        "\n",
        "    #valid_c1 = valid.select_dtypes('number')  # drop all categorical variables\n",
        "    #valid_c1 = valid_c1[valid_c1['machine_age'] < 40]\n",
        "    valid_c1 = valid.fillna(-1)\n",
        "    #valid_c1 = valid_c1.dropna()  # drop all rows with missing values\n",
        "    # plots\n",
        "    # features_list = ['machine_age']\n",
        "    # sns.pairplot(valid_c1[features_list + ['ModelID']])\n",
        "    # plt.show()\n",
        "\n",
        "    #summission\n",
        "    # Ensure the validation data has the same features as the training data\n",
        "    X_valid = valid_c1.set_index('SalesID')[X.columns]\n",
        "    y_valid_pred = model.predict(X_valid)\n",
        "    y_valid_pred = pd.Series(y_valid_pred, index=X_valid.index, name='SalePrice')\n",
        "    # Print predictions for validation data\n",
        "    #print(\"Predictions for validation data:\")\n",
        "    #print(y_valid_pred)\n",
        "    #print('mean avg: ' + str(y_valid_pred.mean()))\n",
        "\n",
        "    # Create a submission file  -# add date-time to csv file name\n",
        "\n",
        "    # timestamp = datetime.now().isoformat()\n",
        "    timestamp = datetime.now().isoformat().replace(':', '_')\n",
        "    filename = f'submission_{timestamp}.csv'\n",
        "    y_valid_pred.to_csv(filename)\n",
        "    print (pd.Series(model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False))\n",
        "\n",
        "# Press the green button in the gutter to run the script.\n",
        "if __name__ == '__main__':\n",
        "   # plot_plt()\n",
        "    RandomForest()\n",
        "\n",
        "# See PyCharm help at https://www.jetbrains.com/help/pycharm/\n"
      ]
    }
  ]
}